{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 75, 50)            228000    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 75, 100)           40400     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 75, 50)            5050      \n",
      "_________________________________________________________________\n",
      "crf_3 (CRF)                  (None, 75, 7)             420       \n",
      "=================================================================\n",
      "Total params: 273,870\n",
      "Trainable params: 273,870\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MAX_LEN = 75\n",
    "EMBEDDING = 50\n",
    "\n",
    "leis_dir = 'leis_vetadas/'\n",
    "leis = []\n",
    "leis_split = []\n",
    "words = []\n",
    "for fname in os.listdir(leis_dir):\n",
    "    with open(leis_dir+fname, \"r\", encoding=\"utf-8\") as f:\n",
    "        r = f.read()\n",
    "        leis.append(r)\n",
    "        leis_split.append(r.split('**VETO**'))\n",
    "        file_words = text_to_word_sequence(r)\n",
    "        # file_words = split_words(r)\n",
    "        words += file_words\n",
    "\n",
    "vocab = list(set(words))\n",
    "n_words = len(vocab)\n",
    "\n",
    "tags = [\"ok\",'b-ok','e-ok',\"veto\",'b-veto','e-veto']\n",
    "n_tags = len(tags)\n",
    "\n",
    "word2idx = {w: i + 2 for i, w in enumerate(vocab)}\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "# Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "# Model definition\n",
    "input = Input(shape=(MAX_LEN,))\n",
    "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
    "                  input_length=MAX_LEN, mask_zero=True)(input)  # default: 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.15))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags+1)  # CRF layer, n_tags+1(PAD)\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.load_weights(\"model/alesp-2019-05-24.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ee3ce1c324a419b9a4a520447896a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='sentence', placeholder='Type your sentence here'), Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Custom Tokenizer\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "    \n",
    "def get_prediction(sentence):\n",
    "    test_sentence = tokenize(sentence) # Tokenization\n",
    "    s_len = len(test_sentence)\n",
    "    t_sentences = []\n",
    "    #print('len(test_sentence)', s_len)\n",
    "    # Preprocessing\n",
    "    for step in range(math.ceil(s_len / MAX_LEN)):\n",
    "        sentence1 = test_sentence[75*step:75*(step+1)]\n",
    "        #print(\"*************************************\")\n",
    "        #print(sentence1)\n",
    "        #print(\"*************************************\")\n",
    "        t_sentences.append(pad_sequences(sequences=[[word2idx.get(w, 0) for w in sentence1]],\n",
    "                           padding=\"post\", value=word2idx[\"PAD\"], maxlen=MAX_LEN)[0])\n",
    "\n",
    "    p = model.predict(np.array(t_sentences))\n",
    "    p = np.array([np.argmax(p1, axis=-1) for p1 in p])\n",
    "    # Visualization\n",
    "\n",
    "    for w, pred in zip(test_sentence, np.ndarray.flatten(p)):\n",
    "        #print(\"{:15}: {:5}\".format(w, idx2tag[pred]))\n",
    "        if idx2tag[pred] in ['b-veto', 'veto', 'e-veto']:\n",
    "            sys.stdout.write(\"\\x1b[31m\"+w+\"\\x1b[0m \")\n",
    "        else:\n",
    "            sys.stdout.write(w+' ')\n",
    "\n",
    "interact_manual(get_prediction, sentence=widgets.Textarea(placeholder='Type your sentence here'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
